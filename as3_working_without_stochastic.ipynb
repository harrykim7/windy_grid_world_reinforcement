{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ns is  [3, 0]\nS_next is [3, 1]\nS_next after wind is [3, 1]\ns is  [3, 1] a is 1 next =  [3, 1]\n\ns is  [3, 1]\nS_next is [4, 2]\nS_next after wind is [4, 2]\ns is  [4, 2] a is 5 next =  [4, 2]\n\ns is  [4, 2]\nS_next is [5, 3]\nS_next after wind is [5, 3]\ns is  [5, 3] a is 5 next =  [5, 3]\n\ns is  [5, 3]\nS_next is [6, 4]\nS_next after wind is [5, 4]\ns is  [5, 4] a is 5 next =  [5, 4]\n\ns is  [5, 4]\nS_next is [5, 5]\nS_next after wind is [4, 5]\ns is  [4, 5] a is 1 next =  [4, 5]\n\ns is  [4, 5]\nS_next is [5, 6]\nS_next after wind is [4, 6]\ns is  [4, 6] a is 5 next =  [4, 6]\n\ns is  [4, 6]\nS_next is [5, 7]\nS_next after wind is [3, 7]\ns is  [3, 7] a is 5 next =  [3, 7]\n7\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "CISC 453 Assignment 3\n",
    "Windy Grid World\n",
    "Harry Kim, Ryan D'gama\n",
    "'''\n",
    "\n",
    "import numpy as np \n",
    "import random \n",
    "\n",
    "def create_grid(): #creates size*size grid with the coordinates as values\n",
    "    aList =[]\n",
    "    for y in range(7):\n",
    "        aList.append([10])\n",
    "        for x in range(size):\n",
    "            aList[y].append([])\n",
    "\n",
    "    return aList\n",
    "def choose_action(epsilon,s,Q,actions):\n",
    "    #epsilon greedy\n",
    "    if (random.uniform(0,1) > epsilon):\n",
    "        #exploit\n",
    "        a = find_best_action(Q,s)\n",
    "        return a\n",
    "    else:\n",
    "        #explore\n",
    "        a = random.randint(0,actions-1)\n",
    "        return a\n",
    "\n",
    "def find_best_action(Q,s):\n",
    "    qlist =[]\n",
    "    #add every q(s,a) for all a in s\n",
    "    for action in Q:\n",
    "        qlist.append(action[s[0],s[1]])\n",
    "    #find the best a \n",
    "    a = np.argmax(qlist) \n",
    "    return a \n",
    "\n",
    "def take_action(s,a):\n",
    "    next_s = s.copy()\n",
    "    if a ==0:   #North\n",
    "        next_s[0] -= 1\n",
    "    elif a ==1:   #East\n",
    "        next_s[1] += 1\n",
    "    elif a ==2:   #South\n",
    "        next_s[0] += 1\n",
    "    elif a ==3:   #West\n",
    "        next_s[1] -= 1\n",
    "    elif a ==4:   #NorthEast\n",
    "        next_s[0] -= 1\n",
    "        next_s[1] += 1\n",
    "    elif a ==5:   #SouthEast\n",
    "        next_s[0] += 1\n",
    "        next_s[1] += 1\n",
    "    elif a ==6:   #SouthWest\n",
    "        next_s[0] += 1\n",
    "        next_s[1] -= 1\n",
    "    elif a ==7:   #NorthWest\n",
    "        next_s[0] -= 1\n",
    "        next_s[1] -= 1\n",
    "\n",
    "    return next_s\n",
    "\n",
    "def out_of_bounds(s): \n",
    "    #returns boolean value of if the state is out of the grid\n",
    "    if s[0] < 0 or s[0] > 6:\n",
    "        return True\n",
    "    if s[1] < 0 or s[1] > 9: \n",
    "        return True \n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def apply_wind(next_s,s,wind):\n",
    "    #you have to apply the original state's wind to the new state\n",
    "    column = s[1]\n",
    "    #make sure the column didn't go out of bounce, if so it just passes on to reward\n",
    "    if column >= 0 and column <= 9:\n",
    "        if next_s[0] >= 0 and next_s[0] <= 6:\n",
    "            next_s[0] = next_s[0] - wind[column]\n",
    "            #if wind pushes us out, it stays by the wall, reward doesn't punish us for it\n",
    "            if next_s[0] < 0:\n",
    "                next_s[0] = 0\n",
    "    return next_s\n",
    "\n",
    "def reward(og,coord,goal):\n",
    "    #returns rewards and also makes sure the cell does not go out of bounds\n",
    "    if out_of_bounds(coord) == True: #cell is out of bounds\n",
    "        return [og,-5] #return to original state with -1 reward\n",
    "\n",
    "    elif coord == goal: #reached the goal, reward = 10 \n",
    "        return [coord,10]\n",
    "\n",
    "    else:\n",
    "        return [coord,-1] #if not move on with reward = 0\n",
    "\n",
    "def get_path(Q,s,goal,wind):\n",
    "    #prints out the path \n",
    "    total_moves = []\n",
    "    while s != goal:\n",
    "        total_moves.append(s)\n",
    "        a = find_best_action(Q,s)\n",
    "        \n",
    "        print('\\ns is ',s)\n",
    "        next_s = take_action(s,a)\n",
    "        print('S_next is',next_s)\n",
    "        next_s = apply_wind(next_s,s,wind)\n",
    "        print('S_next after wind is', next_s)\n",
    "        next_s, r = reward(s,next_s,goal)\n",
    "        s = next_s\n",
    "        print(\"s is \",s, \"a is\",a,'next = ',next_s)\n",
    "    print(len(total_moves))\n",
    "\n",
    "def stochastic_wind():\n",
    "    #creates stochastic winds with variation of 1 from the mean\n",
    "    wind = [0,0,0,1,1,1,2,2,1,0]\n",
    "    for i in range(len(wind)):\n",
    "        if wind[i] != 0 :\n",
    "            wind[i] = random.randint(wind[i]-1 , wind[i] +1)\n",
    "    return wind\n",
    "\n",
    "def sarsa(episodes,actions, epsilon, alpha, gamma, s_wind):\n",
    "    #parameters\n",
    "    epsilon = epsilon\n",
    "    alpha = alpha\n",
    "    gamma = gamma\n",
    "\n",
    "    episodes = episodes \n",
    "    actions = actions #8 is kings moves, 4 is cardinal \n",
    "    start = [3,0]\n",
    "    goal = [3,7]\n",
    "    wind = [0,0,0,1,1,1,2,2,1,0]\n",
    "\n",
    "    #Q -  8 of 7x10 arrays\n",
    "    Q = np.zeros((actions,7,10))\n",
    "\n",
    "    for j in range(episodes):\n",
    "\n",
    "        s = start\n",
    "        a = choose_action(epsilon,s,Q,actions)\n",
    "                \n",
    "        if s_wind == True:\n",
    "            wind = stochastic_wind()\n",
    "\n",
    "        while s != goal:\n",
    "        #for i in range(1000):\n",
    "            #take action A, observe s and r \n",
    "            next_s = take_action(s,a)\n",
    "            #print('\\n start loop')\n",
    "            #print('S is ',s)\n",
    "            #print('S_next is',next_s)\n",
    "            next_s = apply_wind(next_s,s,wind)\n",
    "            #print('S_next after wind is', next_s)\n",
    "            next_s, r = reward(s,next_s,goal)\n",
    "            #print('Final next_s is:',next_s)\n",
    "            next_a = choose_action(epsilon,next_s,Q,actions)\n",
    "\n",
    "            #update \n",
    "            #print(\"s is \",s, \"a is\",a, \"r is\",r, \"next s is\",next_s, \"next a is \",next_a)\n",
    "            Q[a][s[0]][s[1]] = Q[a][s[0]][s[1]] + alpha*(r + gamma*Q[next_a][next_s[0]][next_s[1]] - Q[a][s[0]][s[1]])       \n",
    "            s = next_s\n",
    "            a = next_a\n",
    "\n",
    "\n",
    "    #print best path\n",
    "    s = start\n",
    "    #print(Q)\n",
    "    get_path(Q,s,goal,wind)\n",
    "    return Q\n",
    "\n",
    "sar= sarsa(episodes = 100000, actions = 8, epsilon = 0.3, alpha = 0.001, gamma= 0.9, s_wind=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 0, 0, 1, 0, 1, 3, 3, 2, 0]\n"
     ]
    }
   ],
   "source": [
    "def stochastic_wind():\n",
    "    #creates stochastic winds with variation of 1 from the mean\n",
    "    wind = [0,0,0,1,1,1,2,2,1,0]\n",
    "    for i in range(len(wind)):\n",
    "        if wind[i] != 0 :\n",
    "            wind[i] = random.randint(wind[i]-1 , wind[i] +1)\n",
    "    return wind\n",
    "print(stochastic_wind())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ns is  [3, 0]\nS_next is [4, 1]\nS_next after wind is [4, 1]\ns is  [4, 1] a is 5 next =  [4, 1]\n\ns is  [4, 1]\nS_next is [5, 2]\nS_next after wind is [5, 2]\ns is  [5, 2] a is 5 next =  [5, 2]\n\ns is  [5, 2]\nS_next is [4, 3]\nS_next after wind is [4, 3]\ns is  [4, 3] a is 4 next =  [4, 3]\n\ns is  [4, 3]\nS_next is [5, 4]\nS_next after wind is [4, 4]\ns is  [4, 4] a is 5 next =  [4, 4]\n\ns is  [4, 4]\nS_next is [5, 5]\nS_next after wind is [4, 5]\ns is  [4, 5] a is 5 next =  [4, 5]\n\ns is  [4, 5]\nS_next is [5, 6]\nS_next after wind is [4, 6]\ns is  [4, 6] a is 5 next =  [4, 6]\n\ns is  [4, 6]\nS_next is [5, 7]\nS_next after wind is [3, 7]\ns is  [3, 7] a is 5 next =  [3, 7]\n7\n"
     ]
    }
   ],
   "source": [
    "def Q_learning(episodes,actions, epsilon, alpha, gamma, s_wind = True):\n",
    "    #parameters\n",
    "    epsilon = 0.3\n",
    "    alpha = 0.001\n",
    "    gamma = 0.9\n",
    "\n",
    "    episodes = episodes #8 is kings moves, 4 is cardinal \n",
    "    actions = actions\n",
    "    start = [3,0]\n",
    "    goal = [3,7]\n",
    "    wind = [0,0,0,1,1,1,2,2,1,0]\n",
    "\n",
    "    #Q -  8 of 7x10 arrays\n",
    "    Q = np.zeros((actions,7,10))\n",
    "\n",
    "    for _ in range(episodes):\n",
    "        if s_wind == True:\n",
    "            wind = stochastic_wind()\n",
    "        s = start\n",
    "        #print('yes we are still running')\n",
    "        while s != goal:\n",
    "            #take action A, observe s and r \n",
    "            a = choose_action(epsilon,s,Q,actions)\n",
    "            next_s = take_action(s,a)\n",
    "            #print('next_s before',next_s)\n",
    "            next_s = apply_wind(next_s,s,wind)\n",
    "            #print('next_s after',next_s)\n",
    "            next_s, r = reward(s,next_s,goal)\n",
    "            best_a = find_best_action(Q,next_s)\n",
    "\n",
    "            #update \n",
    "            #print(\"s is \",s, \"a is\",a, \"r is\",r, \"next s is\",next_s)\n",
    "            Q[a][s[0]][s[1]] = Q[a][s[0]][s[1]] + alpha*(r + gamma*Q[best_a][next_s[0]][next_s[1]] - Q[a][s[0]][s[1]])       \n",
    "            s = next_s\n",
    "    \n",
    "    #print best path\n",
    "    s = start\n",
    "\n",
    "    get_path(Q,s,goal,wind)\n",
    "    #print(Q)\n",
    "    return Q\n",
    "q_learn= Q_learning(episodes = 100000, actions = 8, epsilon = 0.1, alpha = 0.1, gamma= 0.9, s_wind = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[3, 0]\n[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": []
  }
 ]
}